{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "22ada6d3-7599-443e-84da-260a1c2706a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from df import enhance, init_df\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "from IPython.display import Audio #listen: ipd.Audio(real.detach().cpu().numpy(), rate=FS)\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import pandas as pd\n",
    "import torchmetrics.audio as M\n",
    "from speechmos import dnsmos\n",
    "from datetime import datetime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "396217a0-3ffd-411f-898d-1d4b6b53ccec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rep_list(short, long):\n",
    "    reps = int(np.ceil(len(long) / len(short)))\n",
    "    short *= reps\n",
    "    short = short[:len(long)]\n",
    "    return short\n",
    "    \n",
    "def plot_tensor(x):\n",
    "    plt.plot(x.cpu().detach().numpy())\n",
    "\n",
    "\n",
    "\n",
    "def extend_signal(signal, target_length):\n",
    "    \"\"\"\n",
    "    Extend a signal by repeating it if it's shorter than the target length.\n",
    "    \n",
    "    Args:\n",
    "    signal (torch.Tensor): Input signal.\n",
    "    target_length (int): Desired length of the extended signal.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Extended signal.\n",
    "    \"\"\"\n",
    "    current_length = signal.size(0)\n",
    "    if current_length < target_length:\n",
    "        repetitions = target_length // current_length\n",
    "        remainder = target_length % current_length\n",
    "        extended_signal = signal.repeat(repetitions)\n",
    "        if remainder > 0:\n",
    "            extended_signal = torch.cat((extended_signal, signal[:remainder]), dim=0)\n",
    "        return extended_signal\n",
    "    else:\n",
    "        return signal\n",
    "\n",
    "def load_audio(apath):\n",
    "    audio, fs = torchaudio.load(apath)\n",
    "    if fs != FS:\n",
    "        #print('resampling')\n",
    "        resampler = torchaudio.transforms.Resample(fs, FS)\n",
    "        audio = resampler(audio)    \n",
    "    if len(audio.shape) > 1:\n",
    "            audio = audio[0,:]\n",
    "    return audio\n",
    "\n",
    "def power(signal):\n",
    "    return np.mean(signal**2)\n",
    "    \n",
    "def add_batch_results(meta, pesq, stoi, sisdri, srmr, dnsmos_result, model_name, batch_size, df):\n",
    "    idx = len(df)\n",
    "    for i in range(batch_size):\n",
    "        df.loc[idx+i, 'train_rirs'] = TRAINRIR_NAMES[model_name]\n",
    "        df.loc[idx+i, 'eval_rirs'] = rir_path.split('/')[-1].split('_')[0]\n",
    "        df.loc[idx+i, 'model'] = model_name\n",
    "        df.loc[idx+i, 'speech'] = os.path.join(*meta[0][i].split('/')[6:])\n",
    "        df.loc[idx+i, 'noise'] = os.path.join(*meta[1][i].split('/')[6:])\n",
    "        df.loc[idx+i, 'rir'] = os.path.join(*meta[2][i].split('/')[4:])\n",
    "        df.loc[idx+i, 'noisy_snr'] = meta[3][i].item()\n",
    "        df.loc[idx+i, 'sisdri'] = sisdri[i]\n",
    "        df.loc[idx+i, 'pesq'] = pesq[i]\n",
    "        df.loc[idx+i, 'stoi'] = stoi[i]\n",
    "        df.loc[idx+i, 'srmr'] = srmr[i]        \n",
    "        df.loc[idx+i, 'ovrl_mos'] = dnsmos_result[i]['ovrl_mos']\n",
    "        df.loc[idx+i, 'sig_mos'] = dnsmos_result[i]['sig_mos']\n",
    "        df.loc[idx+i, 'bak_mos'] = dnsmos_result[i]['bak_mos']\n",
    "        df.loc[idx+i, 'p808_mos'] = dnsmos_result[i]['p808_mos']\n",
    "    return df\n",
    "    \n",
    "class DFN_dataset(Dataset):\n",
    "    def __init__(self, speech_path, noise_path, rir_path, reverberant_noises):\n",
    "        print('Initializing dataset...')\n",
    "        self.speech_path = speech_path\n",
    "        self.noise_path = noise_path\n",
    "        self.rir_path = rir_path\n",
    "        self.reverberant_noises = reverberant_noises\n",
    "        \n",
    "        # load speech paths\n",
    "        self.speech_paths = []\n",
    "        with open(speech_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                self.speech_paths.append(line.rstrip()) \n",
    "        #errors = []\n",
    "        #with open('dns_test_errors.txt', 'r') as file:\n",
    "        #    lines = file.readlines()\n",
    "        #    for line in lines:\n",
    "        #        errors.append(line.rstrip()) \n",
    "        #self.speech_paths = [item for item in self.speech_paths if item not in errors]\n",
    "        # we filter out all speech that does not come from read_speech\n",
    "        #self.speech_paths = [item for item in self.speech_paths if (item.split('/')[7]=='read_speech' or item.split('/')[7]=='read_speech')]\n",
    "\n",
    "        self.snrs = np.random.uniform(low = 0, high = 30, size = len(self.speech_paths))\n",
    "        # load noise paths\n",
    "        self.noise_paths = []\n",
    "        with open(noise_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                self.noise_paths.append(line.rstrip()) \n",
    "\n",
    "        # load rir paths\n",
    "        self.rir_paths = []\n",
    "        with open(rir_path, 'r') as file:\n",
    "            lines = file.readlines()\n",
    "            for line in lines:\n",
    "                self.rir_paths.append(line.rstrip()) \n",
    "\n",
    "        self.noise_paths = rep_list(self.noise_paths, self.speech_paths)\n",
    "        self.rir_paths = rep_list(self.rir_paths, self.speech_paths)\n",
    "        print('All paths loaded.')\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.speech_paths)\n",
    "\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        clean = load_audio(self.speech_paths[idx])\n",
    "        # handle weird case where speech is silence\n",
    "        if len(clean) >= FS*DURATION:\n",
    "            speech_nrgy = torch.mean(clean[:FS*DURATION]**2)\n",
    "        else:\n",
    "            speech_nrgy = torch.mean(clean **2)\n",
    "        if speech_nrgy == 0:\n",
    "            clean = load_audio(self.speech_paths[0])\n",
    "\n",
    "        noise = load_audio(self.noise_paths[int(idx % len(self.noise_paths))])\n",
    "        \n",
    "        # handle silent rir\n",
    "        rir = load_audio(self.rir_paths[int(idx % len(self.rir_paths))])\n",
    "        rir_nrgy = torch.mean(rir**2)\n",
    "        if rir_nrgy == 0:\n",
    "            #print('silent rir')\n",
    "            rir = torch.zeros(FS)\n",
    "            rir[300] = 1.\n",
    "\n",
    "        \n",
    "        # we extend speech and noise if too short\n",
    "        if len(clean) < FS * DURATION:\n",
    "            clean = extend_signal(clean, FS*DURATION)\n",
    "        if len(noise) < FS * DURATION:\n",
    "            noise = extend_signal(noise, FS*DURATION)\n",
    "\n",
    "        # back to numpy for easy conv\n",
    "        clean = clean.numpy()\n",
    "        noise = noise.numpy()\n",
    "        rir = rir.numpy()\n",
    "            \n",
    "        # we choose the signal chunk with more energy (to avoid silent chunks)\n",
    "        nchunks = len(clean) // (FS*DURATION)\n",
    "        chunks = np.split(clean[: FS * DURATION * nchunks], nchunks)\n",
    "        powers = np.array([power(x) for x in chunks])\n",
    "        clean = clean[np.argmax(powers) * FS * DURATION : (np.argmax(powers) + 1 ) *  FS * DURATION]\n",
    "        \n",
    "        nchunks = len(noise) // (FS*DURATION)\n",
    "        chunks = np.split(noise[: FS * DURATION * nchunks], nchunks)\n",
    "        powers = np.array([power(x) for x in chunks])\n",
    "        noise = noise[np.argmax(powers) * FS * DURATION : (np.argmax(powers) + 1 ) *  FS * DURATION]\n",
    "\n",
    "        #handle silent noise\n",
    "        noise_nrgy = power(noise)\n",
    "        if noise_nrgy == 0.:\n",
    "            #print('silent noise sample, using white noise')\n",
    "            noise = np.random.randn( FS * DURATION )\n",
    "\n",
    "        # we set the SNR\n",
    "        ini_snr = 10 * np.log10(power(clean) / power(noise))\n",
    "        noise_gain_db = ini_snr - self.snrs[idx]\n",
    "        noise *= np.power(10, noise_gain_db/20)\n",
    "\n",
    "        # we normalize to 0.9 if mixture is close to clipping\n",
    "        clips = np.max(np.abs(clean + noise))\n",
    "        if clips >= 0.9:\n",
    "            clips /= 0.9\n",
    "            noise /= clips\n",
    "            clean /= clips\n",
    "        # or to -18dBfs if smaller than that:\n",
    "        elif clips <= 10**(-18/20):\n",
    "            clips /= 10**(-18/20)\n",
    "            noise /= clips \n",
    "            clean /= clips    \n",
    "\n",
    "        # apply rir \n",
    "        revspeech = sig.fftconvolve(clean, rir, 'full')\n",
    "        # synchronize reverberant with anechoic\n",
    "        lag = np.where(np.abs(rir) >= 0.5*np.max(np.abs(rir)))[0][0]\n",
    "        #lag = np.argmax(np.abs(rir))\n",
    "\n",
    "        revspeech = revspeech[lag:FS*DURATION + lag]\n",
    "\n",
    "        # enforce energy conservation\n",
    "        revspeech *= np.sqrt(power(clean) / power(revspeech)) \n",
    "\n",
    "        # apply RIR to noise too if needed\n",
    "        if self.reverberant_noises:\n",
    "            rnoise = sig.fftconvolve(noise, rir, 'full')\n",
    "            rnoise = rnoise[lag:FS*DURATION + lag]\n",
    "            rnoise *= np.sqrt(power(noise) / power(rnoise))\n",
    "            noise = rnoise\n",
    "        noisy = revspeech + noise\n",
    "        #noisy = revspeech\n",
    "        # check for Nans\n",
    "        if np.any(np.isnan(noisy)):\n",
    "            print('noisy nan')\n",
    "        if np.any(np.isnan(clean)):\n",
    "            print('clean nan')\n",
    "        noisy = torch.from_numpy(noisy)\n",
    "        clean = torch.from_numpy(clean)\n",
    "        meta = [self.speech_paths[idx], self.noise_paths[int(idx % len(self.noise_paths))], self.rir_paths[int(idx % len(self.rir_paths))], self.snrs[idx].item()]\n",
    "        return noisy.float(), clean.float(), meta\n",
    "# dataset check\n",
    "'''\n",
    "for rir_path in rir_paths:\n",
    "    print(rir_path)\n",
    "    dataset = DFN_dataset(speech_path, noise_path, rir_path, reverberant_noises)\n",
    "    dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True) \n",
    "    for x in tqdm.tqdm(dataloader):\n",
    "        noisy, clean = x\n",
    "''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9181744d-f761-46af-bdbf-d429f66ab5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "FS = 48000\n",
    "DURATION = 4 #time in seconds of the eval chunk\n",
    "TRAINRIR_NAMES = {'D01_sb_none_NH_mono': 'singleband' , 'D02_mb_none_NH_mono': 'multiband', \n",
    "            'D03_mb_rec_NH_left': 'recdirectivity', 'D05_mb_srcrec_NH_left': 'recsourcedirectivity',\n",
    "            'D00_DNS5': 'DNS5'}\n",
    "\n",
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    TORCH_DEVICE = \"cuda\"\n",
    "else:\n",
    "    TORCH_DEVICE = \"cpu\"\n",
    "\n",
    "batch_size = 1\n",
    "num_workers = 8\n",
    "reverberant_noises = True\n",
    "speech_path = '/home/ubuntu/Data/DFN/textfiles/readspeech_set.txt'\n",
    "noise_path = '/home/ubuntu/Data/DFN/textfiles/test_set_noise.txt'\n",
    "dns_mos_path = '/home/ubuntu/enric/DNS-Challenge/DNSMOS/DNSMOS'\n",
    "\n",
    "rir_paths = ['/home/ubuntu/enric/guso_interspeech24/real_rirs.txt',\n",
    "             '/home/ubuntu/Data/DFN/textfiles/singleband_test_rir.txt',\n",
    "'/home/ubuntu/Data/DFN/textfiles/multiband_test_rir.txt',\n",
    "'/home/ubuntu/Data/DFN/textfiles/recdirectivity_left_test_rir.txt',\n",
    "'/home/ubuntu/Data/DFN/textfiles/recsourcedirectivity_left_test_rir.txt']\n",
    "\n",
    "model_names = list(TRAINRIR_NAMES.keys())\n",
    "results_path = 'results'\n",
    "\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "\n",
    "\n",
    "# Disable the GPU\n",
    "if not use_gpu:\n",
    "    os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"\"\n",
    "if not os.path.exists(results_path):\n",
    "    # Create the directory\n",
    "    os.makedirs(results_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "d6f48b1c-3300-4969-af91-8fe5f086e013",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = model_names[0]\n",
    "rir_path = rir_paths[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f73372b3-2163-4beb-ba79-1fc49bef1a3b",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initializing dataset...\n",
      "All paths loaded.\n",
      "\u001b[32m2024-09-26 12:08:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D01_sb_none_NH_mono\u001b[0m\n",
      "\u001b[32m2024-09-26 12:08:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2024-09-26 12:08:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D01_sb_none_NH_mono/checkpoints/model_118.ckpt.best with epoch 118\u001b[0m\n",
      "\u001b[32m2024-09-26 12:08:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2024-09-26 12:08:43\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "downsampler = torchaudio.transforms.Resample(FS, 16000)\n",
    "#pesq_single = M.PerceptualEvaluationSpeechQuality(16000, 'wb').to(TORCH_DEVICE)\n",
    "sisdr_single = M.ScaleInvariantSignalDistortionRatio(zero_mean=True).to(TORCH_DEVICE)\n",
    "#srmr_single = M.SpeechReverberationModulationEnergyRatio(FS).to(TORCH_DEVICE)\n",
    "sdr = M.SignalDistortionRatio()\n",
    "\n",
    "df = pd.DataFrame(columns=['train_rirs', 'eval_rirs', 'model', 'speech', 'noise', 'rir', 'noisy_snr', 'squim_stoi', 'squim_pesq', 'squim_sisdr'])\n",
    "model_path = pjoin('/home/ubuntu/Data/DFN', model_name)\n",
    "dataset = DFN_dataset(speech_path, noise_path, rir_path, reverberant_noises)\n",
    "dataloader = DataLoader(dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers, drop_last=True) \n",
    "model, df_state, _ = init_df(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "17935d93-cbe2-421b-b9af-bbea20f9f3a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def SISDR(s, s_hat):\n",
    "    \"\"\"Computes the Scale-Invariant SDR as in [1]_.\n",
    "    References\n",
    "    ----------\n",
    "    .. [1] Le Roux, Jonathan, et al. \"SDR–half-baked or well done?.\" ICASSP 2019-2019 IEEE International Conference on\n",
    "    Acoustics, Speech and Signal Processing (ICASSP). IEEE, 2019.\n",
    "    Parameters:\n",
    "        s: targets of any shape\n",
    "        s_hat: corresponding estimates of any shape\n",
    "    \"\"\"\n",
    "    s = torch.from_numpy(s)\n",
    "    s_hat = torch.from_numpy(s_hat)\n",
    "    s = s.view(-1)\n",
    "    EPS = torch.finfo(s.dtype).eps\n",
    "    s_hat = s_hat.view(-1)\n",
    "    a = (torch.dot(s_hat, s) * s) / ((s ** 2).sum() + EPS)\n",
    "    b = a - s_hat\n",
    "    return 10*torch.log10(((a*a).sum()) / ((b*b).sum()+EPS))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "791b81f3-46a9-4eda-a083-62ab0ab343fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(170.5150, dtype=torch.float64)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SISDR(np.array(3.), np.array(5.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3e1af837-8fd9-4e24-98b0-3d901b7f75f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(166.0780, dtype=torch.float64)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SISDR(np.array(5.), np.array(3.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1645b6ea-33db-4e78-ac77-dbe914321d1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "SISDR(np.array(3.), np.array(5.))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "bd4490b8-cb1c-4c5d-95ee-3d8213a8df0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                                                                                                                                                                                                 | 0/41194 [00:01<?, ?it/s]\n"
     ]
    }
   ],
   "source": [
    "for noisy, clean, meta in tqdm.tqdm(dataloader):\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "0ff89e2a-516c-4b68-be13-a46f7b16e9f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3716)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SISDR(clean.numpy(), noisy.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b8c3e655-e59c-4b13-ad56-ee2d1faab923",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(0.3716)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "SISDR(noisy.numpy(), clean.numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "0d76b377-77de-4f95-b824-98a9fdc68c02",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sidr seems invertible except for a single value .-."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "627c9b63-b1a3-479d-b580-71bdeaf76ea9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9681)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr(clean, noisy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f0fa5e42-a7a7-4c13-a95d-a999a761add0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(3.4515)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sdr(noisy, clean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b62bf0d-cb16-4392-9ca8-6fa207b1276e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sdr is not"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26c40ac2-4892-4282-a5fc-68204f3548e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = dataset.speech_paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5942ffe1-a84d-4b6e-bba1-52c41817f41d",
   "metadata": {},
   "outputs": [],
   "source": [
    "set([y.split('/')[7] for y in x])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b50a651-0274-4071-8a40-2c26f0351c3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy, clean, meta, rir, lag, noise = dataset[20014]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58ec9a8b-e93a-49ed-b663-fcdc72562dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3622340-9063-4fd7-a411-a44a43c61636",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy = noisy.unsqueeze(0)\n",
    "clean = clean.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fbf942b8-f2c3-4099-b28e-f5e3b77b2511",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced = enhance(model, df_state, noisy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a7d71c1-d9ca-48e9-9ce4-d0a489b9f5a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy_n = noisy.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48f0bae6-2162-44e8-a22d-38768b1ff5e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_n = clean.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "057ede6f-d7f3-4d0f-905c-2845b8310f92",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced_n = enhanced.detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75799209-455e-49ba-98a8-41f44942377c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(noisy_n[0,:])\n",
    "plt.plot(clean_n[0,:])\n",
    "plt.plot(noisy_n[0,:]) #reverberant\n",
    "\n",
    "#plt.plot(enhanced_n[0,130000:134000])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a103c503-e7e6-4168-9a4e-985ca6312147",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_single(noisy, clean).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5fe0d66e-bccf-4528-ba21-bb4b8d9fc9fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_single(enhanced, clean).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de4a012c-95c2-4d88-a6c1-f4c65d0f35e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_single(enhanced, clean).item() - sisdr_single(noisy, clean).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df7cebb-6a93-4cf6-a539-8adacb4f18c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_rir(clean, rir, noise):\n",
    "    # apply rir \n",
    "    revspeech = sig.fftconvolve(clean, rir, 'full')\n",
    "    # synchronize reverberant with anechoic\n",
    "    lag = np.where(np.abs(rir) >= 0.5*np.max(np.abs(rir)))[0][0]\n",
    "    #lag = np.argmax(np.abs(rir))\n",
    "\n",
    "    revspeech = revspeech[lag:FS*DURATION + lag]\n",
    "\n",
    "    # enforce energy conservation\n",
    "    revspeech *= np.sqrt(power(clean) / power(revspeech)) \n",
    "    noisy = revspeech + noise\n",
    "    #noisy = revspeech\n",
    "    # check for Nans\n",
    "    if np.any(np.isnan(noisy)):\n",
    "        print('noisy nan')\n",
    "    if np.any(np.isnan(clean)):\n",
    "        print('clean nan')\n",
    "    noisy = torch.from_numpy(noisy)\n",
    "    clean = torch.from_numpy(clean)\n",
    "    return clean.unsqueeze(0), noisy.unsqueeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34f27376-cf59-4208-82cd-bddfca7aca01",
   "metadata": {},
   "outputs": [],
   "source": [
    "xclean , xnoisy = apply_rir(clean_n[0], rir, noise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e244162-aeac-4e96-a975-69513e3dddfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#plt.plot(noisy_n[0,:])\n",
    "plt.plot(xclean[0,:])\n",
    "plt.plot(xnoisy[0,:]) #reverberant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "958021cb-cdc7-4ebb-aa17-53fcc6fd1c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_single(xnoisy, xclean).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f64c762-bba8-413a-bd78-15a5915fd661",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4fae8fcb-a1a9-4bff-9ba5-64841db1fb92",
   "metadata": {},
   "outputs": [],
   "source": [
    "#now we add some noise to rir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a279916-3cd2-4168-a070-526b7b60c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(rir)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9e2a3b2-3741-4b0d-9d5e-d25445aac04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag = np.where(np.abs(rir) >= 0.5*np.max(np.abs(rir)))[0][0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e80d9bcd-653f-4320-b832-3a4f55c1d16e",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoise_len = len(rir)-lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07d346a8-afe4-4ecd-9fbd-200fa6c4fde5",
   "metadata": {},
   "outputs": [],
   "source": [
    "nnoise =np.random.randn(nnoise_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b8101d5-6127-4197-86f0-3f0e6c9a4ff8",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(nnoise)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933f5c0a-94f9-4e24-a7a9-65e2935c0f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "xaxis = np.linspace(1, nnoise_len, nnoise_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8fc645a7-3509-4189-8adc-5f2e13844259",
   "metadata": {},
   "outputs": [],
   "source": [
    "exponential = np.exp(0.001*xaxis)[::-1]/1e7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d883bdf5-7d7d-4729-803d-cbf1b1544763",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "plt.plot(nnoise * exponential/3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64faba35-9dc6-469b-9ae5-eee1b7852db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rirnoise = np.hstack((np.zeros(len(rir)-nnoise_len), 0.3*nnoise * exponential/3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1703b4a-55a7-4de8-bd54-42ac1842b996",
   "metadata": {},
   "outputs": [],
   "source": [
    "rirnoise_levels = np.linspace(0, 1, 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6142550-51ca-4aad-853b-27537c3a5db4",
   "metadata": {},
   "outputs": [],
   "source": [
    "rirnoise_levels[::-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2eeb67a8-a7ca-4090-8999-0ab4334f4f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('results_realRIRs/D01_sb_none_NH_mono_evaluatedOn_real.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aac305e-ba13-423c-99ee-aa90d224ce2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['rir']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f9ddba-42dd-4129-b03a-b728a41ee09a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we check this are not in the trainin set\n",
    "trainrirs = []\n",
    "with open('/home/ubuntu/Data/DFN/textfiles/training_set_rirs.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        trainrirs.append(line.rstrip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "574d6a1f-140e-4fc3-a635-36d7405b9798",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainrirs = [x.split('/home/ubuntu/Data/')[1] for x in trainrirs]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d29deb-b659-493f-9874-3aca6730934b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for rir in df['rir']:\n",
    "    print(rir in trainrirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88b8b039-b23b-487b-88c6-26e6f1024675",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df.iloc[0].dnsmos_sig_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b7105c1-74ed-482a-8477-2a829d169e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b07c78-6ba7-449a-a0e1-828beca3e6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].lsd_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ba6ee74-0e74-49a0-a8c2-772b8f81e901",
   "metadata": {},
   "outputs": [],
   "source": [
    "spksim_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f5ba6c2-1446-4d5e-bcaf-95627d144a28",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].squim_stoi_e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92b51057-fefe-472f-9781-398920371d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].srmr_c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db92e5a7-3fbf-44a5-9f07-9d6d837c74fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.iloc[0].srmr_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1be1060d-8d00-4b5c-bf45-47e90b5eb1ab",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sisdrs_noisy = []\n",
    "sisdrs_enhanced = []\n",
    "rirnoise_nrgys = []\n",
    "for rirnoise_level in rirnoise_levels[::-1]:\n",
    "    nrir = rir+rirnoise*rirnoise_level\n",
    "    rirnoise_nrgys.append(np.sum((np.abs(rirnoise*rirnoise_level))**2))\n",
    "    xclean , xnoisy = apply_rir(clean_n[0], nrir, noise)\n",
    "    enhanced = enhance(model, df_state, xnoisy.float())\n",
    "    sisdrs_noisy.append(sisdr_single(xnoisy, xclean).item())\n",
    "    sisdrs_enhanced.append(sisdr_single(enhanced, xclean).item())\n",
    "\n",
    "    plt.subplot(2,2,1)\n",
    "    plt.plot(nrir)\n",
    "    plt.title('Adding noise to the RIR')\n",
    "plt.subplot(2,2,2)\n",
    "plt.plot(np.array(rirnoise_nrgys), sisdrs)\n",
    "#plt.plot(sisdrs)\n",
    "plt.xlabel('rir noise energy')\n",
    "plt.ylabel('sisdr(noisy, clean)')\n",
    "plt.title('decreases SISDR')\n",
    "plt.tight_layout()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b7e3f23-ad28-4460-ba00-4e8a16887fd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(xnoisy.numpy()[0], rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa690918-d1d3-4531-b8c4-8e069bdd2f10",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(rirnoise_nrgys) , sisdrs_noisy)\n",
    "plt.plot(np.array(rirnoise_nrgys), sisdrs_enhanced)\n",
    "plt.legend(['sisdr(noisy, clean)', 'sisdr(enhanced, clean)'])\n",
    "plt.xlabel('rir noise energy')\n",
    "plt.grid(True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99385580-d1a1-4d17-a3a3-2c154e15efd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#TODO -> afegir noise als synthetic fins que sigui negatiu????\n",
    "# opció b) calcular increments de totes les metriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "288fa9b9-7838-4035-8521-82949b8037d4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b31289e7-7571-43a1-ac02-af4b9a956ac9",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=np.linspace(1,200, 200)\n",
    "#sisdr_single(noisy[0,:-k], clean[0,k:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf76c606-37e7-424d-9a40-4c6644ca6c5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "ks=[int(x) for x in ks]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5ebd7eb-5011-420d-8133-97d2a1ef5066",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdrs = []\n",
    "for k in ks:\n",
    "    sisdrs.append(sisdr_single(noisy[0,:-k], clean[0,k:]).item())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd7bdba5-66d6-455d-a7c1-41e39c542725",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdr_single(noisy, clean).item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82d5816d-f5ce-460d-ab09-2eabb2312217",
   "metadata": {},
   "outputs": [],
   "source": [
    "sisdrs=np.array(sisdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f37c3c9-3730-4564-a11b-cb412b8cc2b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(sisdrs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e12be58b-27e8-4623-b76b-4a707a82b630",
   "metadata": {},
   "outputs": [],
   "source": [
    "lag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cbe1dbe-124f-4db5-8981-7a6da7087714",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sisdr falla con real IRs pero no parece un problema de sincornia\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b7eace1-78f8-4fab-8ce8-686e18456da2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# this should be positive! ground truth is noisier than enhanced"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf714788-2f05-4662-8611-9aabedb7ae57",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(noisy_n, rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3a3727f-b9d4-4b5f-9c00-e2078058ec82",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(clean_n, rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "349fdae5-3038-4050-a14d-7630d3735efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "Audio(enhanced_n, rate=FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e369297-d520-4c00-8b2e-82849b8556c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#filter_dnsmos.py: the parameter selection I use the default , there are almost few filtered audios. Is the score too high?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f3598029-1dfb-4a66-b8fe-78d7ff3cab2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "dnsmos.run(clean_n[0,:], 16000) \n",
    "#SIG, BAK and OVR MOS values. 4.2, 4.5, 4.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "628d2ec7-5c4e-472a-96ca-ac6f469b2a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "ovrls = []\n",
    "sigs = []\n",
    "baks = []\n",
    "for noisy, clean, meta in tqdm.tqdm(dataloader):\n",
    "    dnsmos_result = dnsmos.run(clean[0,:].numpy(), 16000) \n",
    "    if dnsmos_result['ovrl_mos'] > 4.0 and dnsmos_result['bak_mos'] > 4.5 and dnsmos_result['sig_mos'] > 4.2:\n",
    "        break\n",
    "    #ovrls.append(dnsmos_result['ovrl_mos'])\n",
    "    #sigs.append(dnsmos_result['sig_mos'])\n",
    "    #baks.append(dnsmos_result['bak_mos'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75d33a33-4a3e-4ccf-a551-68a7d324db9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f289ce3-8fca-45df-a5bf-d156a0fe2604",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77ba62a6-3cae-4b6d-8990-7f8b0483b1db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ded2890b-a782-4aeb-b644-326868468cc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c042ffd3-086d-4c46-9744-19becfd67d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Running evaluation of '+model_name+' evaluated on '+\n",
    "    rir_path.split('/')[-1].split('_')[0]+'RIRs ...')\n",
    "for noisy, clean, meta in tqdm.tqdm(dataloader):\n",
    "    try:\n",
    "        enhanced = enhance(model, df_state, noisy)\n",
    "    except:\n",
    "        print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error while enhancing '+os.path.join(*meta[0][0].split('/')[6:]))\n",
    "    break\n",
    "    '''\n",
    "    downsampler = downsampler.to('cpu')\n",
    "    ds_enhanced = downsampler(enhanced)\n",
    "    didx = len(df)\n",
    "    for i in range(batch_size):\n",
    "        df.loc[didx+i, 'train_rirs'] = TRAINRIR_NAMES[model_name]\n",
    "        df.loc[didx+i, 'eval_rirs'] = rir_path.split('/')[-1].split('_')[0]\n",
    "        df.loc[didx+i, 'model'] = model_name\n",
    "        df.loc[didx+i, 'speech'] = os.path.join(*meta[0][i].split('/')[6:])\n",
    "        df.loc[didx+i, 'noise'] = os.path.join(*meta[1][i].split('/')[6:])\n",
    "        df.loc[didx+i, 'rir'] = os.path.join(*meta[2][i].split('/')[4:])\n",
    "        df.loc[didx+i, 'noisy_snr'] = meta[3][i].item()\n",
    "        try:\n",
    "            # first the CPU metrics\n",
    "            dnsmos_result = dnsmos.run(ds_enhanced[i].numpy(), 16000) \n",
    "            df.loc[didx+i, 'ovrl_mos'] = dnsmos_result['ovrl_mos']\n",
    "            df.loc[didx+i, 'sig_mos'] = dnsmos_result['sig_mos']\n",
    "            df.loc[didx+i, 'bak_mos'] = dnsmos_result['bak_mos']\n",
    "            df.loc[didx+i, 'p808_mos'] = dnsmos_result['p808_mos']\n",
    "        except:\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error getting DNSMOS of '+os.path.join(*meta[0][i].split('/')[6:])+'_'+rir_path+'_'+model_name)\n",
    "            df.loc[didx+i, 'ovrl_mos'] = np.NAN\n",
    "            df.loc[didx+i, 'sig_mos'] = np.NAN\n",
    "            df.loc[didx+i, 'bak_mos'] = np.NAN\n",
    "            df.loc[didx+i, 'p808_mos'] = np.NAN   \n",
    "    # then to GPU\n",
    "    ds_enhanced.to(TORCH_DEVICE)\n",
    "    noisy = noisy.to(TORCH_DEVICE)\n",
    "    clean = clean.to(TORCH_DEVICE)\n",
    "    enhanced = enhanced.to(TORCH_DEVICE)\n",
    "    downsampler_gpu = downsampler.to(TORCH_DEVICE)\n",
    "    for i in range(batch_size):\n",
    "        try:\n",
    "            sisdr_final = sisdr_single(enhanced[i], clean[i]).item() \n",
    "            sisdr_original = sisdr_single(noisy[i], clean[i]).item() \n",
    "            sisdri = sisdr_final - sisdr_original\n",
    "        except:\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error getting SISDR of '+os.path.join(*meta[0][i].split('/')[6:])+'_'+rir_path+'_'+model_name)                    \n",
    "            sisdri = np.NAN\n",
    "        df.loc[didx+i, 'sisdri'] = sisdri\n",
    "        try:\n",
    "            df.loc[didx+i, 'pesq'] = pesq_single(ds_enhanced[i], downsampler_gpu(clean[i])).item()\n",
    "        except:\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error getting PESQ of '+os.path.join(*meta[0][i].split('/')[6:])+'_'+rir_path+'_'+model_name)\n",
    "            df.loc[didx+i, 'pesq'] = np.NAN\n",
    "        try:\n",
    "            df.loc[didx+i, 'stoi'] = stoi_single(enhanced[i], clean[i]).item()\n",
    "        except:\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error getting STOI of '+os.path.join(*meta[0][i].split('/')[6:])+'_'+rir_path+'_'+model_name)                    \n",
    "            df.loc[didx+i, 'stoi'] = np.NAN\n",
    "        try:\n",
    "            df.loc[didx+i, 'srmr'] = srmr_single(enhanced[i]).item()\n",
    "        except:\n",
    "            df.loc[didx+i, 'srmr'] = np.NAN\n",
    "            print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Error getting SRMR of '+os.path.join(*meta[0][i].split('/')[6:])+'_'+rir_path+'_'+model_name)\n",
    "df.to_csv(pjoin(results_path, model_name+'_evaluatedOn_'+rir_path.split('/')[-1].split('_')[0]), index=False)\n",
    "print(datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")+' || Done.')\n",
    "    ''';"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f00f9b8-5240-4147-af21-1406b90389fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchaudio.pipelines import SQUIM_OBJECTIVE, SQUIM_SUBJECTIVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b949d1-2ff7-44e0-b844-5394924f4735",
   "metadata": {},
   "outputs": [],
   "source": [
    "objective_model = SQUIM_OBJECTIVE.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54f726bf-853f-405d-9391-8034101b5808",
   "metadata": {},
   "outputs": [],
   "source": [
    "subjective_model = SQUIM_SUBJECTIVE.get_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5d3ef05-a067-4dfc-ab5a-a3d49d294f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "stoi_hyp, pesq_hyp, si_sdr_hyp = objective_model(downsampler(enhanced))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60410fa-b0cb-430e-a9ff-ff2c6eda7e42",
   "metadata": {},
   "outputs": [],
   "source": [
    "NMR_SPEECH = torchaudio.utils.download_asset(\"tutorial-assets/ctc-decoding/1688-142285-0007.wav\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0120e736-2e05-4ceb-a6d0-1e2c710df62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "nmr_speech, _ = torchaudio.load(NMR_SPEECH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10fd3070-a459-49b9-9564-67c58e30f240",
   "metadata": {},
   "outputs": [],
   "source": [
    "mos = subjective_model(downsampler(enhanced), nmr_speech)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3996cbe7-6fda-46b6-a329-1f1e460568bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ref is reference, inf is enhanced signal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c37603e4-a488-4ddd-bfa8-ad46b65efb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "intru.estoi_metric(clean.squeeze(), enhanced.squeeze(), FS)\n",
    "\n",
    "intru.lsd_metric(clean.numpy(), enhanced.numpy(), FS)[0]\n",
    "\n",
    "intru.mcd_metric(clean.squeeze().numpy(), enhanced.squeeze().numpy(), FS)\n",
    "\n",
    "intru.pesq_metric(clean.squeeze().numpy(), enhanced.squeeze().numpy(), FS)\n",
    "\n",
    "intru.sdr_metric(clean.squeeze().numpy(), enhanced.squeeze().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2df386ec-ca12-4348-9fff-0f5531afbbf2",
   "metadata": {},
   "outputs": [],
   "source": [
    "enhanced.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "778f184e-b86e-40a1-8edf-10fbcb0f6a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "noisy.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2b1b4b8-55b7-4419-96df-570747302a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "torchaudio.save('tmp.wav', enhanced, FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e54c1556-324f-447a-a599-05d96a8aa665",
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_nisqa(nisqa_model, 'tmp.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c53fd8cc-0098-44f2-b84a-44d2b28d2d15",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa3f3ba3-3a30-4d1a-bc25-2e9c1de7366d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# nisqa is non intrusive\n",
    "\n",
    "intru.lsd_metric(np.expand_dims(clean.squeeze().numpy(), 0), np.expand_dims(enhanced.squeeze().numpy(), 0), FS)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "addebce5-49a8-4dec-ad78-d5ac7811a97d",
   "metadata": {},
   "outputs": [],
   "source": [
    "phon.phoneme_similarity_metric(phon_model, clean.squeeze(), enhanced.squeeze(), FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0284b94e-b4b6-4f7a-bab7-bf47369634d2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8942ef6b-1091-404d-91d5-8d6ef98fe437",
   "metadata": {},
   "outputs": [],
   "source": [
    "spksim.speaker_similarity_metric(spksim_model, clean.squeeze(), enhanced.squeeze(), FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b86f446-4a60-4a92-af21-32cef502985b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sbert.speech_bert_score_metric(sbs_model.score, clean.squeeze(), enhanced.squeeze(), FS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466860d0-30c7-470e-932b-6d62dea985ff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dns",
   "language": "python",
   "name": "dns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
