{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "64c261e9-1a20-4c2c-8551-6798357d9833",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/enric/venvs/dns/lib/python3.8/site-packages/df/io.py:9: UserWarning: `torchaudio.backend.common.AudioMetaData` has been moved to `torchaudio.AudioMetaData`. Please update the import path.\n",
      "  from torchaudio.backend.common import AudioMetaData\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torch.nn.functional as F\n",
    "import torchaudio\n",
    "from df import enhance, init_df\n",
    "from os.path import join as pjoin\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import tqdm\n",
    "import time\n",
    "from IPython.display import Audio #listen: ipd.Audio(real.detach().cpu().numpy(), rate=FS)\n",
    "import numpy as np\n",
    "import scipy.signal as sig\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3a6f609a-b0fe-4176-bfd3-7bbc6357cb5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "FS=48000\n",
    "DURATION = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6530cac2-bd42-4d4a-b32b-06aaefb5b05a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extend_signal(signal, target_length):\n",
    "    \"\"\"\n",
    "    Extend a signal by repeating it if it's shorter than the target length.\n",
    "    \n",
    "    Args:\n",
    "    signal (torch.Tensor): Input signal.\n",
    "    target_length (int): Desired length of the extended signal.\n",
    "\n",
    "    Returns:\n",
    "    torch.Tensor: Extended signal.\n",
    "    \"\"\"\n",
    "    current_length = signal.size(0)\n",
    "    if current_length < target_length:\n",
    "        repetitions = target_length // current_length\n",
    "        remainder = target_length % current_length\n",
    "        extended_signal = signal.repeat(repetitions)\n",
    "        if remainder > 0:\n",
    "            extended_signal = torch.cat((extended_signal, signal[:remainder]), dim=0)\n",
    "        return extended_signal\n",
    "    else:\n",
    "        return signal\n",
    "\n",
    "def load_audio(apath):\n",
    "    audio, fs = torchaudio.load(apath)\n",
    "    if fs != FS:\n",
    "        #print('resampling')\n",
    "        resampler = torchaudio.transforms.Resample(fs, FS)\n",
    "        audio = resampler(audio)    \n",
    "    if len(audio.shape) > 1:\n",
    "            audio = audio[0,:]\n",
    "    return audio\n",
    "\n",
    "def power(signal):\n",
    "    return np.mean(signal**2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1b99358a-fa98-4710-ae4e-79a4ae0c0563",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_path = '/home/ubuntu/Data/DFN/textfiles/readspeech_set.txt'\n",
    "noise_path = '/home/ubuntu/Data/DFN/textfiles/test_set_noise.txt'\n",
    "rir_path = '/home/ubuntu/Data/DFN/textfiles/real_rirs.txt'\n",
    "#speakerphone_path = '/home/ubuntu/Data/DFN/textfiles/DNS5_val_speakerphone.txt'\n",
    "#headset_path = '/home/ubuntu/Data/DFN/textfiles/DNS5_val_headset.txt'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "75e67fa3-4c45-41cb-b79b-de080d9d2562",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "speech set loaded. contains 41194 files.\n"
     ]
    }
   ],
   "source": [
    "# load speech wav paths from the textfile\n",
    "speech_paths = []\n",
    "with open(speech_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        speech_paths.append(line.rstrip()) \n",
    "print('speech set loaded. contains '+str(len(speech_paths)) +' files.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c32700d6-c3fd-4683-aa7c-de8af90e70c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load speech wav paths from the textfile\n",
    "noise_paths = []\n",
    "with open(noise_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        noise_paths.append(line.rstrip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0c0eb5f-3fb3-40bb-aa93-af290b37b958",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_paths_val = []\n",
    "noise_paths_train = []\n",
    "with open('/home/ubuntu/Data/DFN/textfiles/training_set_noise.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        noise_paths_train.append(line.rstrip()) \n",
    "with open('/home/ubuntu/Data/DFN/textfiles/validation_set_noise.txt', 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        noise_paths_val.append(line.rstrip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "c0d37d05-31fc-4ea8-b95f-7edcefbbe24c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load speech wav paths from the textfile\n",
    "rir_paths = []\n",
    "with open(rir_path, 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    for line in lines:\n",
    "        rir_paths.append(line.rstrip()) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "58e9a774-25f5-4bd5-a1bd-7de2b71940bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 9565/9565 [00:09<00:00, 1021.86it/s]\n"
     ]
    }
   ],
   "source": [
    "ns = []\n",
    "for n in tqdm.tqdm(noise_paths):\n",
    "    if n not in noise_paths_val:\n",
    "        if n not in noise_paths_train:\n",
    "            ns.append(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4f035281-9f20-4d54-b9b1-9dd3da1f7f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise_paths = ns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "71c32d92-ff7c-4996-a153-cec0dd6010e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "TRAINRIR_NAMES = {'D01_sb_none_NH_mono': 'singleband' , 'D02_mb_none_NH_mono': 'multiband', \n",
    "            'D03_mb_rec_NH_left': 'recdirectivity', 'D05_mb_srcrec_NH_left': 'recsourcedirectivity',\n",
    "            'D00_DNS5': 'DNS5', 'D09_SSmp3d_left' : 'soundspaces'}\n",
    "\n",
    "use_gpu = True\n",
    "if torch.cuda.is_available() and use_gpu:\n",
    "    TORCH_DEVICE = \"cuda\"\n",
    "else:\n",
    "    TORCH_DEVICE = \"cpu\"\n",
    "\n",
    "model_names = list(TRAINRIR_NAMES.keys())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0e220c91-67d3-4d30-925b-2ee14028cf8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we randomly pick 40 speech, noise and real rirs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "bb8dc744-ff17-415e-82d0-2389b69f2afd",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0db384c0-2f44-4255-9f3b-6c50b2975d98",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_paths = np.random.choice(speech_paths, 101)\n",
    "noise_paths = np.random.choice(noise_paths, 101)\n",
    "rir_paths = np.random.choice(rir_paths, 101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "02ad2817-dcf7-44b8-bd20-9883fd9bfc18",
   "metadata": {},
   "outputs": [],
   "source": [
    "#we remove a corrupt file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4afb82-0c87-4faf-8c93-36c3a5139d5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "rir_paths = np.delete(rir_paths, rir_paths=='/home/ubuntu/Data/MIT_IR_Survey/h195_Outside_SuburbanFronyYard_1txts.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "65496afd-8865-41aa-abec-085a23b82320",
   "metadata": {},
   "outputs": [],
   "source": [
    "speech_paths = np.delete(speech_paths, speech_paths=='/home/ubuntu/Data/DNS-Challenge/datasets_fullband/clean_fullband/read_speech/book_02476_chp_0010_reader_09190_12_seg_1.wav')\n",
    "noise_paths = np.delete(noise_paths, noise_paths=='/home/ubuntu/Data/DNS-Challenge/datasets_fullband/noise_fullband/door_Freesound_validated_470511_7.wav')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f42df698-cadb-49d1-b410-a90ce2c41a71",
   "metadata": {},
   "outputs": [],
   "source": [
    "snrs = np.linspace(0, 30, 8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ca3baab0-f479-4e1f-993f-50d3075224ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-14 13:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on torch 2.1.1+cu121\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on host op-mm-guestxr\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D01_sb_none_NH_mono\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:07\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "fatal: not a git repository (or any of the parent directories): .git\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[32m2025-04-14 13:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D01_sb_none_NH_mono/checkpoints/model_118.ckpt.best with epoch 118\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:10\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "76\n",
      "clipping...\n",
      "\u001b[32m2025-04-14 13:17:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D02_mb_none_NH_mono\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:34\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D02_mb_none_NH_mono/checkpoints/model_116.ckpt.best with epoch 116\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:35\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "19\n",
      "clipping...\n",
      "76\n",
      "clipping...\n",
      "\u001b[32m2025-04-14 13:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D03_mb_rec_NH_left\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D03_mb_rec_NH_left/checkpoints/model_116.ckpt.best with epoch 116\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:17:54\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "76\n",
      "clipping...\n",
      "\u001b[32m2025-04-14 13:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D05_mb_srcrec_NH_left\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D05_mb_srcrec_NH_left/checkpoints/model_119.ckpt.best with epoch 119\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:12\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "76\n",
      "clipping...\n",
      "94\n",
      "clipping...\n",
      "\u001b[32m2025-04-14 13:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D00_DNS5\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D00_DNS5/checkpoints/model_119.ckpt.best with epoch 119\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:30\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "76\n",
      "clipping...\n",
      "87\n",
      "clipping...\n",
      "\u001b[32m2025-04-14 13:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mLoading model settings of D09_SSmp3d_left\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mInitializing model `deepfilternet3`\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mFound checkpoint /home/ubuntu/Data/DFN/D09_SSmp3d_left/checkpoints/model_114.ckpt.best with epoch 114\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mRunning on device cuda:0\u001b[0m\n",
      "\u001b[32m2025-04-14 13:18:46\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36mDF\u001b[0m | \u001b[1mModel loaded\u001b[0m\n",
      "76\n",
      "clipping...\n",
      "87\n",
      "clipping...\n",
      "Done.\n"
     ]
    }
   ],
   "source": [
    "for model_name in model_names:\n",
    "    model_path = pjoin('/home/ubuntu/Data/DFN', model_name)\n",
    "    model, df_state, _ = init_df(model_path)\n",
    "    \n",
    "    s = snrs.repeat(int(np.ceil(len(speech_paths)/len(snrs))))\n",
    "    path = pjoin('listening_test_drynoise')\n",
    "    for i, speech_pth in enumerate(speech_paths):\n",
    "        snr = s[i]\n",
    "        clean = load_audio(speech_paths[i])\n",
    "        if i < 10:\n",
    "            idx = '0'+str(i)    \n",
    "        else:\n",
    "            idx = str(i)\n",
    "        noise = load_audio(noise_paths[i])\n",
    "        try:\n",
    "            rir = load_audio(rir_paths[i])\n",
    "        except:\n",
    "            np.random.seed(0)\n",
    "            rir = load_audio(np.random.choice(rir_paths, 1)[0])\n",
    "    \n",
    "        # we extend speech and noise if too short\n",
    "        if len(clean) < FS * DURATION:\n",
    "            clean = extend_signal(clean, FS*DURATION)\n",
    "        if len(noise) < FS * DURATION:\n",
    "            noise = extend_signal(noise, FS*DURATION)\n",
    "                       \n",
    "        # back to numpy for easy conv\n",
    "        clean = clean.numpy()\n",
    "        noise = noise.numpy()\n",
    "        rir = rir.numpy()\n",
    "            \n",
    "        # we choose the signal chunk with more energy (to avoid silent chunks)\n",
    "        nchunks = len(clean) // (FS*DURATION)\n",
    "        chunks = np.split(clean[: FS * DURATION * nchunks], nchunks)\n",
    "        powers = np.array([power(x) for x in chunks])\n",
    "        clean = clean[np.argmax(powers) * FS * DURATION : (np.argmax(powers) + 1 ) *  FS * DURATION]\n",
    "        \n",
    "        nchunks = len(noise) // (FS*DURATION)\n",
    "        chunks = np.split(noise[: FS * DURATION * nchunks], nchunks)\n",
    "        powers = np.array([power(x) for x in chunks])\n",
    "        noise = noise[np.argmax(powers) * FS * DURATION : (np.argmax(powers) + 1 ) *  FS * DURATION]\n",
    "    \n",
    "        #handle silent noise\n",
    "        noise_nrgy = power(noise)\n",
    "        if noise_nrgy == 0.:\n",
    "            #print('silent noise sample, using white noise')\n",
    "            noise = np.random.randn( FS * DURATION )\n",
    "    \n",
    "        # we set the SNR\n",
    "        ini_snr = 10 * np.log10(power(clean) / power(noise))\n",
    "        noise_gain_db = ini_snr - snr\n",
    "        noise *= np.power(10, noise_gain_db/20)\n",
    "    \n",
    "        # we normalize to 0.9 if mixture is close to clipping\n",
    "        clips = np.max(np.abs(clean + noise))\n",
    "        if clips >= 0.9:\n",
    "            clips /= 0.9\n",
    "            noise /= clips\n",
    "            clean /= clips\n",
    "        # or to -18dBfs if smaller than that:\n",
    "        elif clips <= 10**(-18/20):\n",
    "            clips /= 10**(-18/20)\n",
    "            noise /= clips \n",
    "            clean /= clips    \n",
    "    \n",
    "        # apply rir \n",
    "        revspeech = sig.fftconvolve(clean, rir, 'full')\n",
    "        # synchronize reverberant with anechoic\n",
    "        lag = np.where(np.abs(rir) >= 0.5*np.max(np.abs(rir)))[0][0] # we take as direct sound the first value (from the left) that's at most -6dB from max\n",
    "    \n",
    "        revspeech = revspeech[lag:FS*DURATION + lag]\n",
    "    \n",
    "        # enforce energy conservation\n",
    "        revspeech *= np.sqrt(power(clean) / power(revspeech)) \n",
    "    \n",
    "        #apply RIR to noise too if needed\n",
    "        #if self.reverberant_noises:\n",
    "        #rnoise = sig.fftconvolve(noise, rir, 'full')\n",
    "        #rnoise = rnoise[lag:FS*DURATION + lag]\n",
    "        #rnoise *= np.sqrt(power(noise) / power(rnoise))\n",
    "        #noise = rnoise\n",
    "        noisy = revspeech + noise\n",
    "        noisy = torch.from_numpy(noisy)\n",
    "        enhanced = enhance(model, df_state, noisy.unsqueeze(0))\n",
    "        enhanced *= np.sqrt(power(clean) / power(enhanced.numpy())) \n",
    "        if torch.max(enhanced) > 1.0:\n",
    "            print(i)\n",
    "            print('clipping...')\n",
    "            clip_factor = torch.max(enhanced)\n",
    "            enhanced/=clip_factor\n",
    "            clean/=clip_factor.item()\n",
    "        torchaudio.save(pjoin(path, idx+'_snr_'+str(int(np.round(snr)))+'_noisy.flac'), noisy.unsqueeze(0), FS)\n",
    "        torchaudio.save(pjoin(path, idx+'_snr_'+str(int(np.round(snr)))+'_clean.flac'), torch.from_numpy(clean).unsqueeze(0), FS)\n",
    "        torchaudio.save(pjoin(path, idx+'_snr_'+str(int(np.round(snr)))+'_'+model_name+'.flac'), enhanced, FS)\n",
    "print('Done.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a81c9231-741f-4702-92ed-1ebe98719079",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude 18, 19, 76 i 94"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dns",
   "language": "python",
   "name": "dns"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
